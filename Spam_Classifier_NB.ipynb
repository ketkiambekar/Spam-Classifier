{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam_Classifier_NB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMtm8SZbN4dGrvUuE5Iq3pP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketkiambekar/Spam-Classifier/blob/main/Spam_Classifier_NB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8nZGdiNwJ4I"
      },
      "source": [
        "# SMS Spam Classifier using Naive Bayes "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IyXJJPKwPBO"
      },
      "source": [
        "In this program, we implement a spam classifier using a very common generative algorithm called Naive Bayes. The Data Corpus used is freely available on Kaggle. Inspite of assuming that word occurences are independent of each other (hence the moniker \"Naive\"), we get a surprisingly good accuracy of 98% with this classifier.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNpk32ZjbiLV"
      },
      "source": [
        "To begin with, set your messages in the first cell and play all cells. The program will classify your messagess as spam or ham (not spam).  Feel free to add your own messages to this list.\n",
        "\n",
        "NOTE: Before running this colab, make sure the train, test and val csv files are uploaded to the files section on the left pane. You can find the dataset files on the github page. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fvXDIJUbd10"
      },
      "source": [
        "Messages = []\n",
        "Messages.append(\"Urgent! Claim your prize of $2000 now\")\n",
        "Messages.append(\"Good luck with School, Anette\")\n",
        "Messages.append(\"Buy our new drug to give you guaranteed results\")\n",
        "Messages.append(\"Let's go shopping tomorrow!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aKIA9m3G6GE"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIhQ3xNPz9_Q"
      },
      "source": [
        "The first step is to clean and normalize our data corpus. We remove punctuations and special characters. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBmQkUxMHrjL"
      },
      "source": [
        "def get_words(message):\n",
        "    \"\"\"Get the normalized list of words from a message string.\n",
        "\n",
        "    This function should split a message into words, normalize them, and return\n",
        "    the resulting list. For simplicity, you should split on whitespace, not\n",
        "    punctuation or any other character. For normalization, you should convert\n",
        "    everything to lowercase.  Please do not consider the empty string (\" \") to be a word.\n",
        "\n",
        "    Args:\n",
        "        message: A string containing an SMS message\n",
        "\n",
        "    Returns:\n",
        "       The list of normalized words from the message.\n",
        "    \"\"\"\n",
        "    #remove punctuations in the message\n",
        "    punc='~`!@#$%^&*(),.:\\\";\\'-+=_0123456789?Â£'\n",
        "    for p in punc:\n",
        "        message = message.replace(p,'')\n",
        "    words =  message.lower().split(' ')\n",
        "    return words\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTAKFolO0CEP"
      },
      "source": [
        "We then create a dictionary out of the cleaned list of words. We only select words that occur more than 5 times in all of the Data Corpus. The words are mapped to their indices. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ8ej4z6H6JP"
      },
      "source": [
        "def create_dictionary(messages):\n",
        "    \"\"\"Create a dictionary mapping words to integer indices.\n",
        "\n",
        "    This function should create a dictionary of word to indices using the provided\n",
        "    training messages. Use get_words to process each message.\n",
        "\n",
        "    Rare words are often not useful for modeling. Please only add words to the dictionary\n",
        "    if they occur in at least five messages.\n",
        "\n",
        "    Args:\n",
        "        messages: A list of strings containing SMS messages\n",
        "\n",
        "    Returns:\n",
        "        A python dict mapping words to integers.\n",
        "    \"\"\"\n",
        "    counts=dict()\n",
        "    for msg in messages:\n",
        "\n",
        "        words = get_words(msg)\n",
        "\n",
        "        #remove duplicates\n",
        "        words = list(dict.fromkeys(words))\n",
        "\n",
        "        #count words\n",
        "        for word in words:\n",
        "            counts[word] = counts.get(word,0)+1\n",
        "\n",
        "    my_dict={}\n",
        "    my_list=[]\n",
        "\n",
        "    #consider only keys where count >=5\n",
        "    for key in counts.keys():\n",
        "        if counts[key]>=5:\n",
        "            my_list.append(key)\n",
        "\n",
        "    my_list.sort()    \n",
        "    for i in range (0,len(my_list)):\n",
        "        my_dict[my_list[i]]=i\n",
        "    return my_dict\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9IzCKsn0GNS"
      },
      "source": [
        "\n",
        "We then create a feature vectors (2D numpy array) for our train messages corresponding to all words in our dictionary, 0 representing absence of word in our message and 1 indicating the presence of the word in our message. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGqJ-ZC4IBkz"
      },
      "source": [
        "\n",
        "def transform_text(messages, word_dictionary):\n",
        "    \"\"\"Transform a list of text messages into a numpy array for further processing.\n",
        "\n",
        "    This function creates a numpy array that contains the number of times each word\n",
        "    of the vocabulary appears in each message. \n",
        "    Each row in the resulting array corresponds to each message \n",
        "    and each column corresponds to a word of the vocabulary.\n",
        "\n",
        "    Use the word dictionary to map words to column indices. Ignore words that\n",
        "    are not present in the dictionary. Use get_words to get the words for a message.\n",
        "\n",
        "    Args:\n",
        "        messages: A list of strings where each string is an SMS message.\n",
        "        word_dictionary: A python dict mapping words to integers.\n",
        "\n",
        "    Returns:\n",
        "        A numpy array marking the words present in each message.\n",
        "        Where the component (i,j) is the number of occurrences of the\n",
        "        j-th vocabulary word in the i-th message.\n",
        "    \"\"\"\n",
        "    vocab =  sorted(word_dictionary.keys())\n",
        "    vocab_length = len(word_dictionary.keys())\n",
        "    num_messages = len(messages)\n",
        "\n",
        "    arr = np.zeros((num_messages,vocab_length), dtype=np.float128)\n",
        "    for i in range(0,num_messages):\n",
        "        words=get_words(messages[i])\n",
        "          \n",
        "        for word in words:\n",
        "            if word in vocab:\n",
        "                j = vocab.index(word)\n",
        "                arr[i][j]+=1\n",
        "\n",
        "    return arr\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC4We4yg0OZU"
      },
      "source": [
        "We then create our model using the Bayesian formula for conditional probability. \n",
        "\n",
        "Our model has three parameters: \n",
        "\n",
        "phi(j|y1) is the fraction of the spam (y = 1) messages in which a word j does appear.\n",
        "\n",
        "phi(j|y0) is the fraction of the ham (y = 0) messages in which a word j appears.\n",
        "\n",
        "phi(j) is overall probability that a message is spam.\n",
        "\n",
        "We additionally apply Laplace Smoothing, so that words which are not present in our dictionary and therefore exposed to our model for the first time and not automatically given zero weightage. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LxFwiW0cVyX"
      },
      "source": [
        "def fit_naive_bayes_model(matrix, labels):\n",
        "    \"\"\"Fit a naive bayes model.\n",
        "\n",
        "    This function should fit a Naive Bayes model given a training matrix and labels.\n",
        "\n",
        "    The function should return the state of that model.\n",
        "\n",
        "    Feel free to use whatever datatype you wish for the state of the model.\n",
        "\n",
        "    Args:\n",
        "        matrix: A numpy array containing word counts for the training data\n",
        "        labels: The binary (0 or 1) labels for that training data\n",
        "\n",
        "    Returns: The trained model\n",
        "    \"\"\"\n",
        "\n",
        "    phi_y1_arr = []\n",
        "    phi_y0_arr = []\n",
        "    phi_y = 0\n",
        "\n",
        "    num_messages,vocab = matrix.shape\n",
        "\n",
        "    #Split into Spam and non spam matrices\n",
        "    for i in range(0,num_messages):\n",
        "        if labels[i]==1:\n",
        "            phi_y1_arr.append(matrix[i])\n",
        "        else:\n",
        "            phi_y0_arr.append(matrix[i])\n",
        "    \n",
        "    #convert lists to numpy arrays\n",
        "    phi_y1_np = np.array(phi_y1_arr)\n",
        "    phi_y0_np = np.array(phi_y0_arr)\n",
        "\n",
        "    phi_y1 = (1+np.sum(phi_y1_np, axis=0))/(len(phi_y1_np)+vocab)\n",
        "    phi_y0 = (1+np.sum(phi_y0_np, axis=0))/(len(phi_y0_np)+vocab)\n",
        "\n",
        "    phi_y= len(phi_y1_np)/num_messages\n",
        "\n",
        "    return phi_y0, phi_y1, phi_y\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YzJYt2r3Cwq"
      },
      "source": [
        "When Predicting labels, we calculate the maximum log likelihood of a message being spam or ham and compare the two. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gri1rWccat2"
      },
      "source": [
        "def predict_from_naive_bayes_model(model, matrix):\n",
        "    \"\"\"Use a Naive Bayes model to compute predictions for a target matrix.\n",
        "\n",
        "    This function should be able to predict on the models that fit_naive_bayes_model\n",
        "    outputs.\n",
        "\n",
        "    Args:\n",
        "        model: A trained model from fit_naive_bayes_model\n",
        "        matrix: A numpy array containing word counts\n",
        "\n",
        "    Returns: A numpy array containg the predictions from the model\n",
        "    \"\"\"\n",
        "    phi_y0, phi_y1, phi_y = model\n",
        "\n",
        "    matrix[matrix>1]=1\n",
        "\n",
        "    y1 = phi_y1*matrix\n",
        "    y1[y1==0]=1 \n",
        "    y0 = phi_y0*matrix\n",
        "    y0[y0==0]=1 \n",
        "    \n",
        "    num_messages, vocab = matrix.shape\n",
        "\n",
        "    p1= np.exp(np.sum(np.log(y1), axis=1))*phi_y\n",
        "    #denominator = numerator + np.exp(np.sum(np.log(y0), axis=1))*(1-phi_y)\n",
        "\n",
        "    p0= np.exp(np.sum(np.log(y0), axis=1))*(1-phi_y)\n",
        "   \n",
        "    probabilities=[]\n",
        "    for i in range(0,len(p0)):\n",
        "        if p0[i]>=p1[i]:\n",
        "            probabilities.append(0)\n",
        "        else:\n",
        "            probabilities.append(1)\n",
        "    return np.array(probabilities)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al6_Vnea3cAP"
      },
      "source": [
        "Turns out the individual words in and of themselves are indicative of whether a message is spam or not. In the function below, we fetch top 5 words that are most indicatice of a message being spam. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAsA8SGkcfa6"
      },
      "source": [
        "def get_top_five_naive_bayes_words(model, dictionary):\n",
        "    \"\"\"Compute the top five words that are most indicative of the spam (i.e positive) class.\n",
        "\n",
        "    Ues the metric given in part-c as a measure of how indicative a word is.\n",
        "    Return the words in sorted form, with the most indicative word first.\n",
        "\n",
        "    Args:\n",
        "        model: The Naive Bayes model returned from fit_naive_bayes_model\n",
        "        dictionary: A mapping of word to integer ids\n",
        "\n",
        "    Returns: A list of the top five most indicative words in sorted order with the most indicative first\n",
        "    \"\"\"\n",
        "    #vocab =  sorted(dictionary.keys())\n",
        "\n",
        "    reversed_dictionary = {v : k for (k, v) in dictionary.items()}\n",
        "    \n",
        "    phi_y0,phi_y1,phi_y = model\n",
        "\n",
        "    logs = np.log(phi_y1)-np.log(phi_y0) \n",
        "    sorted_args = np.argsort(logs)\n",
        "    top_5 = sorted_args[-5:]    \n",
        "    ret = [reversed_dictionary[i] for i in top_5]\n",
        "\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD6NZwnLdWrF"
      },
      "source": [
        "def load_spam_dataset(tsv_path):\n",
        "    \"\"\"Load the spam dataset from a TSV file\n",
        "\n",
        "    Args:\n",
        "         csv_path: Path to TSV file containing dataset.\n",
        "\n",
        "    Returns:\n",
        "        messages: A list of string values containing the text of each message.\n",
        "        labels: The binary labels (0 or 1) for each message. A 1 indicates spam.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = []\n",
        "    labels = []\n",
        "\n",
        "    with open(tsv_path, 'r', newline='', encoding='utf8') as tsv_file:\n",
        "        reader = csv.reader(tsv_file, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
        "\n",
        "        for label, message in reader:\n",
        "            messages.append(message)\n",
        "            labels.append(1 if label == 'spam' else 0)\n",
        "\n",
        "    return messages, np.array(labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lvmbua4i30oO"
      },
      "source": [
        "Bind it all together in the Main function below. It is also where you can see result of whether your original messages are spam or not. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjjDLbLycxe-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b54aee6e-61a9-4c9a-9c7d-39f8c8abb537"
      },
      "source": [
        "def main():\n",
        "    train_messages, train_labels = load_spam_dataset('spam_train.tsv')\n",
        "    val_messages, val_labels = load_spam_dataset('spam_val.tsv')\n",
        "    test_messages, test_labels = load_spam_dataset('spam_test.tsv')\n",
        "\n",
        "    dictionary = create_dictionary(train_messages)\n",
        "\n",
        "    print('Size of dictionary: ', len(dictionary))\n",
        "\n",
        "  \n",
        "    train_matrix = transform_text(train_messages, dictionary)\n",
        "\n",
        "    #np.savetxt('spam_sample_train_matrix', train_matrix[:100,:])\n",
        "\n",
        "    val_matrix = transform_text(val_messages, dictionary)\n",
        "    test_matrix = transform_text(test_messages, dictionary)\n",
        "\n",
        "    naive_bayes_model = fit_naive_bayes_model(train_matrix, train_labels)\n",
        "\n",
        "    naive_bayes_predictions_v = predict_from_naive_bayes_model(naive_bayes_model, val_matrix)\n",
        "\n",
        "    #np.savetxt('spam_naive_bayes_predictions', naive_bayes_predictions)\n",
        "\n",
        "    naive_bayes_accuracy_v = np.mean(naive_bayes_predictions_v == val_labels)\n",
        "\n",
        "    print('\\nNaive Bayes had an accuracy of {} on the validation set'.format(naive_bayes_accuracy_v))\n",
        "\n",
        "    naive_bayes_predictions = predict_from_naive_bayes_model(naive_bayes_model, test_matrix)\n",
        "\n",
        "    naive_bayes_accuracy = np.mean(naive_bayes_predictions == test_labels)\n",
        "\n",
        "    print('\\nNaive Bayes had an accuracy of {} on the testing set'.format(naive_bayes_accuracy))\n",
        "\n",
        "    top_5_words = get_top_five_naive_bayes_words(naive_bayes_model, dictionary)\n",
        "\n",
        "    print('\\nThe top 5 indicative words for Naive Bayes are: ', top_5_words)\n",
        "\n",
        "\n",
        "    msg_matrix = transform_text(Messages, dictionary)\n",
        "    spam_or_ham = predict_from_naive_bayes_model(naive_bayes_model, msg_matrix)\n",
        "\n",
        "    for i in range(len(Messages)):\n",
        "      if spam_or_ham[i]==1:\n",
        "        print(\"\\nThe message \\\"{}\\\" is:\\nSPAM!\".format(Messages[i]))\n",
        "      else: \n",
        "        print(\"\\nThe message \\\"{}\\\" is:\\nNOT SPAM!\".format(Messages[i]))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of dictionary:  1498\n",
            "\n",
            "Naive Bayes had an accuracy of 0.9820466786355476 on the validation set\n",
            "\n",
            "Naive Bayes had an accuracy of 0.9874551971326165 on the testing set\n",
            "\n",
            "The top 5 indicative words for Naive Bayes are:  ['guaranteed', 'tone', 'won', 'prize', 'claim']\n",
            "\n",
            "The message \"Urgent! Claim your prize of $2000 now\" is:\n",
            "SPAM!\n",
            "\n",
            "The message \"Good luck with School, Anette\" is:\n",
            "NOT SPAM!\n",
            "\n",
            "The message \"Buy our new drug to give you guaranteed results\" is:\n",
            "SPAM!\n",
            "\n",
            "The message \"Let's go shopping tomorrow!\" is:\n",
            "NOT SPAM!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2EX-nkfuVoR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}